{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.predict_model import get_most_recent_path, prepare_loaders, predict_model, get_model, test_model\n",
    "from src.models.train_model_light import ResNetModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/processed/labeled-images/test\"\n",
    "model_path = get_most_recent_path(\"../../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/version=2.pth\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbps-0-1', 'bbps-2-3', 'cecum', 'dyed-lifted-polyps', 'dyed-resection-margins', 'hemorrhoids', 'ileum', 'impacted-stool', 'polyps', 'retroflex-rectum', 'ulcerative-colitis-grade-0-1', 'ulcerative-colitis-grade-1', 'ulcerative-colitis-grade-1-2', 'ulcerative-colitis-grade-2', 'ulcerative-colitis-grade-2-3', 'ulcerative-colitis-grade-3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/mlops-new/lib/python3.10/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "data_dir_path = '../../'+ data_dir\n",
    "image_dataset = datasets.ImageFolder(data_dir_path)\n",
    "dataloader, dataset_size = prepare_loaders(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = image_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, labels = test_model(model, dataloader, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_mistakes = predictions != labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0], device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0:100][mask_mistakes[0:100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, classes = inputs[:4], classes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(inputs[predictions[0:32]!=classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmishacamry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/studio-lab-user/mlops-new/notebooks/visualization/wandb/run-20220618_020308-znp4obsn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mishacamry/hyperkvasir/runs/znp4obsn\" target=\"_blank\">clear-tree-28</a></strong> to <a href=\"https://wandb.ai/mishacamry/hyperkvasir\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/mlops-new/lib/python3.10/site-packages/torch/utils/data/dataloader.py:487: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batch...\n",
      "1 batch...\n",
      "2 batch...\n",
      "3 batch...\n",
      "4 batch...\n",
      "5 batch...\n",
      "6 batch...\n",
      "7 batch...\n",
      "8 batch...\n",
      "9 batch...\n",
      "10 batch...\n",
      "11 batch...\n",
      "12 batch...\n",
      "13 batch...\n",
      "14 batch...\n",
      "15 batch...\n",
      "16 batch...\n",
      "17 batch...\n",
      "18 batch...\n",
      "19 batch...\n",
      "20 batch...\n",
      "21 batch...\n",
      "22 batch...\n",
      "23 batch...\n",
      "24 batch...\n",
      "25 batch...\n",
      "26 batch...\n",
      "27 batch...\n",
      "28 batch...\n",
      "29 batch...\n",
      "30 batch...\n",
      "31 batch...\n",
      "32 batch...\n",
      "33 batch...\n",
      "34 batch...\n",
      "35 batch...\n",
      "36 batch...\n",
      "37 batch...\n",
      "38 batch...\n",
      "39 batch...\n",
      "40 batch...\n",
      "41 batch...\n",
      "42 batch...\n",
      "43 batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Only 108 Image will be uploaded.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 batch...\n",
      "Skip at batch {i}\n",
      "45 batch...\n",
      "Skip at batch {i}\n",
      "Logging 111 mistakes...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 7.814 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=9.202332â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">clear-tree-28</strong>: <a href=\"https://wandb.ai/mishacamry/hyperkvasir/runs/znp4obsn\" target=\"_blank\">https://wandb.ai/mishacamry/hyperkvasir/runs/znp4obsn</a><br/>Synced 6 W&B file(s), 108 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220618_020308-znp4obsn/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "images = []\n",
    "batch_size = dataloader.batch_size\n",
    "wandb.init(project='hyperkvasir')\n",
    "for batch in dataloader:\n",
    "    print(f'{i} batch...')\n",
    "    i += 1\n",
    "    \n",
    "    inputs, classes = batch\n",
    "    inputs = inputs.to(device)\n",
    "    classes = classes.to(device)\n",
    "    batch_predictions = predictions[i*batch_size:(i+1)*batch_size]\n",
    "    mistake_indexes = mask_mistakes[i*batch_size:(i+1)*batch_size]\n",
    "    if len(classes) != len(mistake_indexes):\n",
    "        print('Skip at batch {i}')\n",
    "        continue\n",
    "    \n",
    "    mistake_classes = classes[mistake_indexes]\n",
    "    mistake_predictions = batch_predictions[mistake_indexes]\n",
    "    mistaken_inputs = inputs[mistake_indexes]\n",
    "    \n",
    "    for j in range(len(mistake_classes)):\n",
    "        im = mistaken_inputs[j]\n",
    "        gt = mistake_classes[j]\n",
    "        pred = mistake_predictions[j]\n",
    "        wandb_im = wandb.Image(im, caption=f'GT: {class_names[gt]} \\nPred: {class_names[pred]}')\n",
    "        images.append(wandb_im)\n",
    "print(f'Logging {len(images)} mistakes...')\n",
    "wandb.log({f\"Mistakes\": images})\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9f47435ec7fc72d9b206f25c823a92b8c51fe7a348721a3f553575f3bdf46ac"
  },
  "kernelspec": {
   "display_name": "mlops-new:Python",
   "language": "python",
   "name": "conda-env-mlops-new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
