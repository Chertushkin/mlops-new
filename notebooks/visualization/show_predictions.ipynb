{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import wandb\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import click\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from torch.optim import lr_scheduler\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "from torchvision import datasets, models, transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.predict_model import get_most_recent_path, prepare_loaders, predict_model, get_model\n",
    "from src.models.train_model_light import ResNetModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"data/processed/labeled-images/test\"\n",
    "model_path = get_most_recent_path(\"../../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../models/version=2.pth\n"
     ]
    }
   ],
   "source": [
    "print(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bbps-0-1', 'bbps-2-3', 'cecum', 'dyed-lifted-polyps', 'dyed-resection-margins', 'hemorrhoids', 'ileum', 'impacted-stool', 'polyps', 'retroflex-rectum', 'ulcerative-colitis-grade-0-1', 'ulcerative-colitis-grade-1', 'ulcerative-colitis-grade-1-2', 'ulcerative-colitis-grade-2', 'ulcerative-colitis-grade-2-3', 'ulcerative-colitis-grade-3']\n"
     ]
    }
   ],
   "source": [
    "data_dir_path = '../../'+ data_dir\n",
    "image_dataset = datasets.ImageFolder(data_dir_path)\n",
    "dataloader, dataset_size = prepare_loaders(data_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = image_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict_model(model, dataloader, dataset_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(inp, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "# inputs, classes = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs, classes = inputs[:4], classes[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a grid from batch\n",
    "# out = torchvision.utils.make_grid(inputs)\n",
    "\n",
    "# imshow(out, title=[class_names[x] for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(inputs[predictions[0:32]!=classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmishacamry\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.18"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/wandb/run-20220617_212418-19dtyhfr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/mishacamry/hyperkvasir/runs/19dtyhfr\" target=\"_blank\">whole-wind-16</a></strong> to <a href=\"https://wandb.ai/mishacamry/hyperkvasir\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 batch...\n",
      "1 batch...\n",
      "2 batch...\n",
      "3 batch...\n",
      "4 batch...\n",
      "5 batch...\n",
      "6 batch...\n",
      "7 batch...\n",
      "8 batch...\n",
      "9 batch...\n",
      "10 batch...\n",
      "11 batch...\n",
      "12 batch...\n",
      "13 batch...\n",
      "14 batch...\n",
      "15 batch...\n",
      "16 batch...\n",
      "17 batch...\n",
      "18 batch...\n",
      "19 batch...\n",
      "20 batch...\n",
      "21 batch...\n",
      "22 batch...\n",
      "23 batch...\n",
      "24 batch...\n",
      "25 batch...\n",
      "26 batch...\n",
      "27 batch...\n",
      "28 batch...\n",
      "29 batch...\n",
      "30 batch...\n",
      "31 batch...\n",
      "32 batch...\n",
      "33 batch...\n",
      "34 batch...\n",
      "35 batch...\n",
      "36 batch...\n",
      "37 batch...\n",
      "38 batch...\n",
      "39 batch...\n",
      "40 batch...\n",
      "41 batch...\n",
      "42 batch...\n",
      "43 batch...\n",
      "44 batch...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: 429 encountered ({\"error\":\"rate limit exceeded\"}), retrying request\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb#ch0000013?line=7'>8</a>\u001b[0m inputs, classes \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb#ch0000013?line=8'>9</a>\u001b[0m batch_predicitions \u001b[39m=\u001b[39m predictions[i\u001b[39m*\u001b[39mbatch_size:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mbatch_size]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb#ch0000013?line=9'>10</a>\u001b[0m mistake_indexes \u001b[39m=\u001b[39m batch_predicitions \u001b[39m!=\u001b[39;49m classes\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb#ch0000013?line=11'>12</a>\u001b[0m mistake_classes \u001b[39m=\u001b[39m classes[mistake_indexes]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/shinkovskiymichael/D/Development/repos/mlops-new/notebooks/visualization/show_predictions.ipynb#ch0000013?line=12'>13</a>\u001b[0m mistake_predictions \u001b[39m=\u001b[39m batch_predicitions[mistake_indexes]\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (32) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "batch_size = dataloader.batch_size\n",
    "wandb.init(project='hyperkvasir')\n",
    "for batch in dataloader:\n",
    "    print(f'{i} batch...')\n",
    "    i += 1\n",
    "    \n",
    "    inputs, classes = batch\n",
    "    batch_predicitions = predictions[i*batch_size:(i+1)*batch_size]\n",
    "    mistake_indexes = batch_predicitions != classes\n",
    "\n",
    "    mistake_classes = classes[mistake_indexes]\n",
    "    mistake_predictions = batch_predicitions[mistake_indexes]\n",
    "    mistaken_inputs = inputs[mistake_indexes]\n",
    "    images = []\n",
    "    for j in range(len(mistake_classes)):\n",
    "        im = mistaken_inputs[j]\n",
    "        gt = mistake_classes[j]\n",
    "        pred = mistake_predictions[j]\n",
    "        wandb_im = wandb.Image(im, caption=f'GT: {class_names[gt]}, Pred: {class_names[pred]}')\n",
    "        images.append(wandb_im)\n",
    "          \n",
    "        wandb.log({f\"Mistakes batch {i}\": images})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e9f47435ec7fc72d9b206f25c823a92b8c51fe7a348721a3f553575f3bdf46ac"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('mlops-new')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
